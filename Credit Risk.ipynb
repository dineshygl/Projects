{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 13 columns):\n",
      "Loan_ID              614 non-null object\n",
      "Gender               601 non-null object\n",
      "Married              611 non-null object\n",
      "Dependents           599 non-null object\n",
      "Education            614 non-null object\n",
      "Self_Employed        582 non-null object\n",
      "ApplicantIncome      614 non-null int64\n",
      "CoapplicantIncome    614 non-null float64\n",
      "LoanAmount           592 non-null float64\n",
      "Loan_Amount_Term     600 non-null float64\n",
      "Credit_History       564 non-null float64\n",
      "Property_Area        614 non-null object\n",
      "Loan_Status          614 non-null object\n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 62.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>LP002978</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>LP002979</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3+</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>LP002983</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>8072</td>\n",
       "      <td>240.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>LP002984</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>7583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>LP002990</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Semiurban</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Loan_ID  Gender Married Dependents Education Self_Employed  \\\n",
       "609  LP002978  Female      No          0  Graduate            No   \n",
       "610  LP002979    Male     Yes         3+  Graduate            No   \n",
       "611  LP002983    Male     Yes          1  Graduate            No   \n",
       "612  LP002984    Male     Yes          2  Graduate            No   \n",
       "613  LP002990  Female      No          0  Graduate           Yes   \n",
       "\n",
       "     ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "609             2900                0.0        71.0             360.0   \n",
       "610             4106                0.0        40.0             180.0   \n",
       "611             8072              240.0       253.0             360.0   \n",
       "612             7583                0.0       187.0             360.0   \n",
       "613             4583                0.0       133.0             360.0   \n",
       "\n",
       "     Credit_History Property_Area Loan_Status  \n",
       "609             1.0         Rural           Y  \n",
       "610             1.0         Rural           Y  \n",
       "611             1.0         Urban           Y  \n",
       "612             1.0         Urban           Y  \n",
       "613             0.0     Semiurban           N  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chesking Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               13\n",
       "Married               3\n",
       "Dependents           15\n",
       "Education             0\n",
       "Self_Employed        32\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount           22\n",
       "Loan_Amount_Term     14\n",
       "Credit_History       50\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chesking Null Values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing Missing values\n",
    "train.Gender = train.Gender.fillna(train.Gender.mode()[0])\n",
    "train.Married = train.Married.fillna(train.Married.mode()[0])\n",
    "train.Dependents = train.Dependents.fillna(train.Dependents.mode()[0])\n",
    "train.Self_Employed = train.Self_Employed.fillna(train.Married.mode()[0])\n",
    "train.LoanAmount = train.LoanAmount.fillna(train.LoanAmount.mean())\n",
    "train.Loan_Amount_Term = train.Loan_Amount_Term.fillna(train.Loan_Amount_Term.mode()[0])\n",
    "train.Credit_History = train.Credit_History.fillna(train.Credit_History.mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID              0\n",
       "Gender               0\n",
       "Married              0\n",
       "Dependents           0\n",
       "Education            0\n",
       "Self_Employed        0\n",
       "ApplicantIncome      0\n",
       "CoapplicantIncome    0\n",
       "LoanAmount           0\n",
       "Loan_Amount_Term     0\n",
       "Credit_History       0\n",
       "Property_Area        0\n",
       "Loan_Status          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID               0\n",
       "Gender               11\n",
       "Married               0\n",
       "Dependents           10\n",
       "Education             0\n",
       "Self_Employed        23\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "LoanAmount            5\n",
       "Loan_Amount_Term      6\n",
       "Credit_History       29\n",
       "Property_Area         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing Missing values\n",
    "test.Gender = test.Gender.fillna(test.Gender.mode()[0])\n",
    "#test.Married = test.Married.fillna(test.Married.mode()[0])\n",
    "test.Dependents = test.Dependents.fillna(test.Dependents.mode()[0])\n",
    "test.Self_Employed = test.Self_Employed.fillna(test.Married.mode()[0])\n",
    "test.LoanAmount = test.LoanAmount.fillna(test.LoanAmount.mean())\n",
    "test.Loan_Amount_Term = test.Loan_Amount_Term.fillna(test.Loan_Amount_Term.mode()[0])\n",
    "test.Credit_History = test.Credit_History.fillna(test.Credit_History.mode()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan_ID              0\n",
       "Gender               0\n",
       "Married              0\n",
       "Dependents           0\n",
       "Education            0\n",
       "Self_Employed        0\n",
       "ApplicantIncome      0\n",
       "CoapplicantIncome    0\n",
       "LoanAmount           0\n",
       "Loan_Amount_Term     0\n",
       "Credit_History       0\n",
       "Property_Area        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a copy\n",
    "train_sam1 = train.copy()\n",
    "test_sam1 = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_sam1.copy()\n",
    "test = test_sam1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(['Loan_ID'], axis=1,inplace=True)\n",
    "test.drop(['Loan_ID'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('Loan_Status',axis=1)\n",
    "train = pd.get_dummies(train, drop_first= True)\n",
    "test = pd.get_dummies(test, drop_first= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.Loan_Status_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logi = LogisticRegression()\n",
    "logi.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = logi.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8455284552845529"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "accuracy_score(y_test,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15, 19],\n",
       "       [ 0, 89]], dtype=int64)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "Logistic = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True,\n",
    "                            intercept_scaling=1, class_weight=None, \n",
    "                            random_state=None, solver='liblinear', max_iter=100,\n",
    "                            multi_class='ovr', verbose=2)\n",
    "Logistic.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = Logistic.predict(x_test)\n",
    "\n",
    "# Making the Confusion Matrix \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15, 19],\n",
       "       [ 0, 89]], dtype=int64)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8455284552845529"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Random = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, min_samples_split=2,\n",
    "                               min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto',\n",
    "                               max_leaf_nodes=None, bootstrap=True, oob_score=False, n_jobs=1, \n",
    "                               random_state=None, verbose=0)\n",
    "Random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = Random.predict(x_test)\n",
    "\n",
    "# Making the Confusion Matrix \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17, 17],\n",
       "       [ 7, 82]], dtype=int64)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.50      0.59        34\n",
      "           1       0.83      0.92      0.87        89\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       123\n",
      "   macro avg       0.77      0.71      0.73       123\n",
      "weighted avg       0.80      0.80      0.79       123\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ADA = AdaBoostClassifier(base_estimator=None, n_estimators=200, learning_rate=1.0)\n",
    "ADA.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 15],\n",
       "       [14, 75]], dtype=int64)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ADA.predict(x_test)\n",
    "\n",
    "# Making the Confusion Matrix \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GradientBoo = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=200, subsample=1.0,\n",
    "                                   min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                                   max_depth=3,\n",
    "                                   init=None, random_state=None, max_features=None, verbose=0)\n",
    "GradientBoo.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17, 17],\n",
       "       [12, 77]], dtype=int64)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = GradientBoo.predict(x_test)\n",
    "\n",
    "# Making the Confusion Matrix \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter optimization using Randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] n_estimators=10 .................................................\n",
      "[CV] .................................. n_estimators=10, total=   0.0s\n",
      "[CV] n_estimators=10 .................................................\n",
      "[CV] .................................. n_estimators=10, total=   0.0s\n",
      "[CV] n_estimators=10 .................................................\n",
      "[CV] .................................. n_estimators=10, total=   0.0s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] .................................. n_estimators=50, total=   0.0s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] .................................. n_estimators=50, total=   0.0s\n",
      "[CV] n_estimators=50 .................................................\n",
      "[CV] .................................. n_estimators=50, total=   0.0s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ................................. n_estimators=100, total=   0.0s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ................................. n_estimators=100, total=   0.0s\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] ................................. n_estimators=100, total=   0.0s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................. n_estimators=200, total=   0.2s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................. n_estimators=200, total=   0.2s\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] ................................. n_estimators=200, total=   0.2s\n",
      "[CV] n_estimators=420 ................................................\n",
      "[CV] ................................. n_estimators=420, total=   0.5s\n",
      "[CV] n_estimators=420 ................................................\n",
      "[CV] ................................. n_estimators=420, total=   0.5s\n",
      "[CV] n_estimators=420 ................................................\n",
      "[CV] ................................. n_estimators=420, total=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 10}, 0.7383077470596204)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaHyperParams = {'n_estimators': [10,50,100,200,420]}\n",
    "gridSearchAda = RandomizedSearchCV(estimator=ADA, param_distributions=adaHyperParams, n_iter=5,\n",
    "                                   scoring='roc_auc', fit_params=None, cv=None, verbose=2).fit(x_train, y_train)\n",
    "gridSearchAda.best_params_, gridSearchAda.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] loss=deviance, max_depth=7, n_estimators=171 ....................\n",
      "[CV] ..... loss=deviance, max_depth=7, n_estimators=171, total=   0.3s\n",
      "[CV] loss=deviance, max_depth=7, n_estimators=171 ....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... loss=deviance, max_depth=7, n_estimators=171, total=   0.3s\n",
      "[CV] loss=deviance, max_depth=7, n_estimators=171 ....................\n",
      "[CV] ..... loss=deviance, max_depth=7, n_estimators=171, total=   0.4s\n",
      "[CV] loss=exponential, max_depth=9, n_estimators=365 .................\n",
      "[CV] .. loss=exponential, max_depth=9, n_estimators=365, total=   0.6s\n",
      "[CV] loss=exponential, max_depth=9, n_estimators=365 .................\n",
      "[CV] .. loss=exponential, max_depth=9, n_estimators=365, total=   0.5s\n",
      "[CV] loss=exponential, max_depth=9, n_estimators=365 .................\n",
      "[CV] .. loss=exponential, max_depth=9, n_estimators=365, total=   0.5s\n",
      "[CV] loss=deviance, max_depth=7, n_estimators=207 ....................\n",
      "[CV] ..... loss=deviance, max_depth=7, n_estimators=207, total=   0.4s\n",
      "[CV] loss=deviance, max_depth=7, n_estimators=207 ....................\n",
      "[CV] ..... loss=deviance, max_depth=7, n_estimators=207, total=   0.4s\n",
      "[CV] loss=deviance, max_depth=7, n_estimators=207 ....................\n",
      "[CV] ..... loss=deviance, max_depth=7, n_estimators=207, total=   0.4s\n",
      "[CV] loss=deviance, max_depth=2, n_estimators=33 .....................\n",
      "[CV] ...... loss=deviance, max_depth=2, n_estimators=33, total=   0.0s\n",
      "[CV] loss=deviance, max_depth=2, n_estimators=33 .....................\n",
      "[CV] ...... loss=deviance, max_depth=2, n_estimators=33, total=   0.0s\n",
      "[CV] loss=deviance, max_depth=2, n_estimators=33 .....................\n",
      "[CV] ...... loss=deviance, max_depth=2, n_estimators=33, total=   0.0s\n",
      "[CV] loss=exponential, max_depth=2, n_estimators=244 .................\n",
      "[CV] .. loss=exponential, max_depth=2, n_estimators=244, total=   0.0s\n",
      "[CV] loss=exponential, max_depth=2, n_estimators=244 .................\n",
      "[CV] .. loss=exponential, max_depth=2, n_estimators=244, total=   0.0s\n",
      "[CV] loss=exponential, max_depth=2, n_estimators=244 .................\n",
      "[CV] .. loss=exponential, max_depth=2, n_estimators=244, total=   0.0s\n",
      "[CV] loss=deviance, max_depth=2, n_estimators=13 .....................\n",
      "[CV] ...... loss=deviance, max_depth=2, n_estimators=13, total=   0.0s\n",
      "[CV] loss=deviance, max_depth=2, n_estimators=13 .....................\n",
      "[CV] ...... loss=deviance, max_depth=2, n_estimators=13, total=   0.0s\n",
      "[CV] loss=deviance, max_depth=2, n_estimators=13 .....................\n",
      "[CV] ...... loss=deviance, max_depth=2, n_estimators=13, total=   0.0s\n",
      "[CV] loss=exponential, max_depth=1, n_estimators=365 .................\n",
      "[CV] .. loss=exponential, max_depth=1, n_estimators=365, total=   0.0s\n",
      "[CV] loss=exponential, max_depth=1, n_estimators=365 .................\n",
      "[CV] .. loss=exponential, max_depth=1, n_estimators=365, total=   0.0s\n",
      "[CV] loss=exponential, max_depth=1, n_estimators=365 .................\n",
      "[CV] .. loss=exponential, max_depth=1, n_estimators=365, total=   0.0s\n",
      "[CV] loss=exponential, max_depth=4, n_estimators=86 ..................\n",
      "[CV] ... loss=exponential, max_depth=4, n_estimators=86, total=   0.0s\n",
      "[CV] loss=exponential, max_depth=4, n_estimators=86 ..................\n",
      "[CV] ... loss=exponential, max_depth=4, n_estimators=86, total=   0.0s\n",
      "[CV] loss=exponential, max_depth=4, n_estimators=86 ..................\n",
      "[CV] ... loss=exponential, max_depth=4, n_estimators=86, total=   0.0s\n",
      "[CV] loss=deviance, max_depth=9, n_estimators=359 ....................\n",
      "[CV] ..... loss=deviance, max_depth=9, n_estimators=359, total=   0.5s\n",
      "[CV] loss=deviance, max_depth=9, n_estimators=359 ....................\n",
      "[CV] ..... loss=deviance, max_depth=9, n_estimators=359, total=   0.4s\n",
      "[CV] loss=deviance, max_depth=9, n_estimators=359 ....................\n",
      "[CV] ..... loss=deviance, max_depth=9, n_estimators=359, total=   0.5s\n",
      "[CV] loss=deviance, max_depth=1, n_estimators=162 ....................\n",
      "[CV] ..... loss=deviance, max_depth=1, n_estimators=162, total=   0.0s\n",
      "[CV] loss=deviance, max_depth=1, n_estimators=162 ....................\n",
      "[CV] ..... loss=deviance, max_depth=1, n_estimators=162, total=   0.0s\n",
      "[CV] loss=deviance, max_depth=1, n_estimators=162 ....................\n",
      "[CV] ..... loss=deviance, max_depth=1, n_estimators=162, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:    8.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'loss': 'exponential', 'max_depth': 9, 'n_estimators': 365},\n",
       " 0.7651842195995445)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bHyperParams = {'loss' : ['deviance', 'exponential'],\n",
    "                 'n_estimators': randint(10, 500),\n",
    "                 'max_depth': randint(1,10)}\n",
    "gridSearchGB = RandomizedSearchCV(estimator=GradientBoo, param_distributions=bHyperParams, n_iter=10,\n",
    "                                   scoring='roc_auc', fit_params=None, cv=None, verbose=2).fit(x_train, y_train)\n",
    "gridSearchGB.best_params_, gridSearchGB.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
